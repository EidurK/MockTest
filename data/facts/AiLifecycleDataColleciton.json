{"info":[{"reasoning":"Understanding core lecture topics for the week helps identify essential concepts likely to be in a test about data collection and preparation.","info":"**Lecture Overview & Chapters**: \n- Data Collection and Preparation (Chapter 3) \n- Feature Engineering (Chapter 4) \n- List of topics: Interaction Data, Data Leakage, Data Partitioning, Missing Data, Data Augmentation, Imbalanced Data, Random Sampling, and Data Storage/Versioning."},{"reasoning":"Interaction data is fundamental, and understanding its definition and use in personalization is critical for test questions regarding data quality and user behavior tracking.","info":"**Interaction Data**: \n- Definition: Data collected from user interactions with a system. \n- Key Components: Context, user actions, and outcomes. \n- Applications: Personalizing search results (e.g., reranking based on clicks and dwell time). \n- Analytics Debt: The risk of missing valuable insights if interaction data is not utilized."},{"reasoning":"Data leakage can critically affect model performance. Knowing its causes, examples, and prevention strategies is a high-yield topic.","info":"**Data Leakage**: \n- Definition: Inclusion of information in training data that wouldnâ€™t be available during prediction. \n- Causes: Incorporation of target information, misapplied preprocessing, and use of future data. \n- Examples: Features containing hidden target data (e.g., price per square footage for house pricing) or future features (e.g., late payments when predicting loan repayment). \n- Prevention: Careful feature selection, real-world simulation during validation, consultation with domain experts, and use of sanity checks."},{"reasoning":"Data partitioning is key to ensuring model generalization. It is practical and likely to be framed as best practices in exams.","info":"**Data Partitioning**: \n- Purpose: To assess model performance and prevent overfitting by splitting data into training, validation, and test sets. \n- Best Practices: Partition raw data before preprocessing, preserve group/temporal relationships, and always shuffle data to avoid biased splits."},{"reasoning":"Missing data strategies are common pitfalls in ML projects; testing on how to manage them will likely appear.","info":"**Handling Missing Data**: \n- Importance: Missing data can bias estimates and reduce model validity. \n- Strategies: \n   - Removing rows with missing values, \n   - Imputation using mean/median, extreme values, or regression models, \n   - Using algorithms that handle missing data, \n   - Creating a binary flag for missingness. \n- Note: Imputation should only be done on training data to prevent leakage."},{"reasoning":"Data augmentation, especially contrasting image and text techniques, is a focused topic in feature engineering.","info":"**Data Augmentation**: \n- Definition: Generating additional training samples using transformations. \n- For Images: Techniques include rotation, translation, scaling, flipping, cropping, and libraries like Albumentations and SOLT. \n- For Text: Techniques include synonym replacement, hypernym replacement, noise injection in word vectors, neighbor replacement in embedding space, deletion with BERT prediction, KNN, and back translation. \n- Challenges: Maintaining semantic integrity, contextual relevance, avoiding overfitting, and managing computational resources."},{"reasoning":"Imbalanced data is a testable concept, often with questions on strategies to manage bias in classification.","info":"**Imbalanced Data**: \n- Definition: Unequal class distribution leading to model bias toward the majority class. \n- Techniques to address: \n   - Oversampling (including SMOTE, ADASYN), \n   - Undersampling, \n   - Hybrid approaches, \n   - Considerations on overfitting and loss of information."},{"reasoning":"Understanding sampling techniques is essential for questions on ensuring representative datasets.","info":"**Random Sampling in Data Preparation**: \n- Techniques: \n   - Simple Random Sampling (equal chance for each point), \n   - Stratified Random Sampling (ensures representation across classes), \n   - Cluster-Based Sampling (when stratification is not feasible). \n- Advantages and limitations are discussed."},{"reasoning":"Data storage and versioning are critical for reproducibility in ML projects, a frequent exam focus.","info":"**Data Storage and Versioning**: \n- Data Storage: \n   - Object storage (e.g., Amazon S3) and datalakes are used for unstructured data; \n   - Importance of preserving data format and integrity. \n- Data Versioning: \n   - Ensures reproducibility, flexible update, and tracking of data changes. \n   - Levels: Joint versioning of small datasets with code (using Git or LFS) vs. specialized tools (Data Version Control, Pachyderm) for large assets. \n   - Key aspects include documentation, metadata, and processes for version control and rollback."},{"reasoning":"General best practices may be vital both as direct questions and as guiding principles in data preparation projects.","info":"**General Best Practices**: \n- Automate data transformation to reduce errors and enhance reproducibility. \n- Prioritize data quality over quantity. \n- Thorough documentation including data schema, collection, annotation, partitioning details, pre-processing, excluded data, file formats, and responsibilities for data management."}]}